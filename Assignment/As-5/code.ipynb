{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-As-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/BDA/lib/python3.10/site-packages/joblib/externals/loky/backend/context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[Errno 2] No such file or directory: 'sysctl'\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/BDA/lib/python3.10/site-packages/joblib/externals/loky/backend/context.py\", line 270, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/BDA/lib/python3.10/subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/BDA/lib/python3.10/subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/BDA/lib/python3.10/subprocess.py\", line 1847, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1], dtype=int32),\n",
       " array([[0.33333333, 0.66666667],\n",
       "        [5.        , 1.        ]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define the data matrix\n",
    "X = np.array([[0, 0, 1, 5, 5],\n",
    "              [2, 0, 0, 0, 2]]).T  # Transpose to have samples as rows\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the final cluster assignments and centroids\n",
    "cluster_assignments = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "cluster_assignments, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.461862835113919, 0.5345950037850112, 0.6561346417857326)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initial parameters\n",
    "pi_0, p_0, q_0 = 0.46, 0.55, 0.67\n",
    "observations = np.array([1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
    "n = len(observations)\n",
    "\n",
    "# EM algorithm\n",
    "def expectation_maximization(pi, p, q, observations, iterations=100, tol=1e-6):\n",
    "    for _ in range(iterations):\n",
    "        # E-step: calculate responsibilities (probabilities for latent variables)\n",
    "        responsibility_B = pi * (p ** observations) * ((1 - p) ** (1 - observations))\n",
    "        responsibility_C = (1 - pi) * (q ** observations) * ((1 - q) ** (1 - observations))\n",
    "        total_responsibility = responsibility_B + responsibility_C\n",
    "        gamma_B = responsibility_B / total_responsibility\n",
    "        gamma_C = responsibility_C / total_responsibility\n",
    "\n",
    "        # M-step: update parameters\n",
    "        pi_new = np.mean(gamma_B)\n",
    "        p_new = np.sum(gamma_B * observations) / np.sum(gamma_B)\n",
    "        q_new = np.sum(gamma_C * observations) / np.sum(gamma_C)\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(pi_new - pi) < tol and abs(p_new - p) < tol and abs(q_new - q) < tol:\n",
    "            break\n",
    "\n",
    "        pi, p, q = pi_new, p_new, q_new\n",
    "\n",
    "    return pi, p, q\n",
    "\n",
    "# Run the EM algorithm\n",
    "pi_final, p_final, q_final = expectation_maximization(pi_0, p_0, q_0, observations)\n",
    "\n",
    "pi_final, p_final, q_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13317231632313895,\n",
       " -57.511074469836906,\n",
       " 9.499993564737336,\n",
       " 0.8668276836768611,\n",
       " 32.9848906225897,\n",
       " 20.723370648697156)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Data\n",
    "data = np.array([-67, -48, 6, 8, 14, 16, 23, 24, 28, 29, 41, 49, 56, 60, 75])\n",
    "\n",
    "# Initialize parameters\n",
    "np.random.seed(42)\n",
    "alpha_0, alpha_1 = 0.5, 0.5\n",
    "mu_0, mu_1 = np.random.choice(data, 2, replace=False)\n",
    "sigma_0, sigma_1 = np.std(data), np.std(data)\n",
    "\n",
    "# EM algorithm parameters\n",
    "max_iter = 100\n",
    "tolerance = 1e-4\n",
    "\n",
    "# EM algorithm\n",
    "for iteration in range(max_iter):\n",
    "    # E-step: calculate responsibilities\n",
    "    r0 = alpha_0 * norm.pdf(data, mu_0, sigma_0)\n",
    "    r1 = alpha_1 * norm.pdf(data, mu_1, sigma_1)\n",
    "    total_r = r0 + r1\n",
    "    gamma_0 = r0 / total_r\n",
    "    gamma_1 = r1 / total_r\n",
    "\n",
    "    # M-step: update parameters\n",
    "    new_alpha_0 = gamma_0.mean()\n",
    "    new_alpha_1 = gamma_1.mean()\n",
    "    new_mu_0 = np.sum(gamma_0 * data) / np.sum(gamma_0)\n",
    "    new_mu_1 = np.sum(gamma_1 * data) / np.sum(gamma_1)\n",
    "    new_sigma_0 = np.sqrt(np.sum(gamma_0 * (data - new_mu_0) ** 2) / np.sum(gamma_0))\n",
    "    new_sigma_1 = np.sqrt(np.sum(gamma_1 * (data - new_mu_1) ** 2) / np.sum(gamma_1))\n",
    "\n",
    "    # Convergence check\n",
    "    if (\n",
    "        np.abs(new_mu_0 - mu_0) < tolerance\n",
    "        and np.abs(new_mu_1 - mu_1) < tolerance\n",
    "        and np.abs(new_sigma_0 - sigma_0) < tolerance\n",
    "        and np.abs(new_sigma_1 - sigma_1) < tolerance\n",
    "    ):\n",
    "        break\n",
    "\n",
    "    # Update parameters\n",
    "    alpha_0, alpha_1 = new_alpha_0, new_alpha_1\n",
    "    mu_0, mu_1 = new_mu_0, new_mu_1\n",
    "    sigma_0, sigma_1 = new_sigma_0, new_sigma_1\n",
    "\n",
    "# Final parameters\n",
    "alpha_0, mu_0, sigma_0, alpha_1, mu_1, sigma_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
